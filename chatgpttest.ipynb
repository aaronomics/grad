{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the OpenAI API client\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Identify a problem you are interested in solving: Consider what areas of machine learning you are interested in, and then think of a problem that you would like to solve with machine learning.\n",
      "\n",
      "2. Collect data: Once you have identified a problem, you need to collect data that is relevant to the problem. This could include collecting data from online sources, surveys, or other sources.\n",
      "\n",
      "3. Clean and preprocess the data: Once you have collected the data, you need to clean and preprocess it so that it can be used for machine learning. This includes removing any noise or outliers, normalizing the data, and splitting it into training and testing sets.\n",
      "\n",
      "4. Choose an appropriate algorithm: Once you have cleaned and preprocessed the data, you need to choose an appropriate algorithm for your problem. Consider the type of problem you are trying to solve, the size of the data, and the accuracy you need to achieve.\n",
      "\n",
      "5. Train and evaluate the model: After you have chosen an algorithm, you need to train and evaluate the model. This includes tuning the parameters of the model to optimize the results.\n",
      "\n",
      "6. Deploy the model: Once you have trained and evaluated the model, you need to deploy it. This could involve deploying it as an API, or as a web or mobile application.\n",
      "\n",
      "7. Monitor performance: Finally, you need to monitor the performance of the model over time. This will help you identify any issues or changes that need to be made to improve the model.\n"
     ]
    }
   ],
   "source": [
    "# Set up the model and prompt\n",
    "model_engine = \"text-davinci-003\"\n",
    "# prompt = \"\"\"solve the following with an R script: A random sample of size n1= 25 taken from a normal population with a standard\n",
    "# deviation s1= 5 has a mean of = 80. A second random sample of size n2 = 36 taken\n",
    "# from a normal population with a standard deviation s2 = 3 has a mean of = 75. Find\n",
    "# a 0.94 confidence interval for (μ1 - μ2), & the margin of error. Are the actual means\n",
    "# the same\"\"\"\n",
    "prompt = \"\"\"\n",
    "what should I do for my machine learning research project?\n",
    "\"\"\"\n",
    "\n",
    "# Generate a response\n",
    "completion = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "response = completion.choices[0].text\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens used in the chat session:  108.0\n"
     ]
    }
   ],
   "source": [
    "#This script counts the number of tokens used during a chat session\n",
    "\n",
    "#Define the function to count the tokens\n",
    "def token_count(chat_session):\n",
    "    #Split the chat session into tokens\n",
    "    tokens = chat_session.split(' ')\n",
    "    #num_tokens = len(tokens) \n",
    "    #Return the number of tokens\n",
    "    return len(tokens) * (4/3)\n",
    "\n",
    "#Define the chat session\n",
    "chat_session = response\n",
    "\n",
    "#Call the token_count function\n",
    "token_count = token_count(chat_session)\n",
    "\n",
    "#Print the number of tokens\n",
    "print(\"Number of tokens used in the chat session: \", token_count)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0dc692c0e4c899575203caa3c6ee50046b7b976159587d3bc1af111e3fd11f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
